{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a01d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "import matplotlib.cm as cm\n",
    "from sklearn import  preprocessing, metrics\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7161d4",
   "metadata": {},
   "source": [
    "### Reading the Text Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bce8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv(\"inputs\\reddit_politics_subredditC_multiC.tsv\", sep=\"\\t\")\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd2a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df_sample[\"text\"] # comment\n",
    "docs.replace([np.inf, -np.inf, ''], np.nan, inplace=True)\n",
    "docs.dropna(inplace=True)\n",
    "docs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f401a",
   "metadata": {},
   "source": [
    "### Encoding Texts using the SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-distilroberta-v1')\n",
    "\n",
    "X = np.array(model.encode(docs.to_list()))\n",
    "print(\"mean: \", X.mean())\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f6b1f6",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction & Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db0d8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12538ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced_tsne = TSNE(n_components=2, init='random').fit_transform(X_scaled)\n",
    "tsne_comps = pd.DataFrame(X_reduced_tsne[:,:2], columns=[\"C1\", \"C2\"])\n",
    "X_reduced_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba33c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components=2, whiten=False,svd_solver='auto')\n",
    "pca = PCA(n_components=10, svd_solver='full')\n",
    "X_reduced = pca.fit_transform(X_scaled)\n",
    "print('pca.components: \\n', pca.components_)\n",
    "print('pca.explained variance:\\n', pca.explained_variance_)\n",
    "print('pca.explained variance ratio:\\n', pca.explained_variance_ratio_)\n",
    "print(np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa36a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_comps = pd.DataFrame(X_reduced[:,:2], columns=[\"C1\", \"C2\"])\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6ede9a",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c5e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = np.arange(2,15,1)\n",
    "elbow = []\n",
    "ss = []\n",
    "for k in range_n_clusters:\n",
    "    #iterating through cluster sizes\n",
    "    clusterer = KMeans(n_clusters = k, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X_reduced)\n",
    "    #Finding the average silhouette score\n",
    "    silhouette_avg = silhouette_score(X_reduced, cluster_labels)\n",
    "    ss.append(silhouette_avg)\n",
    "    print(\"For n_clusters =\", k, \"The average silhouette_score is :\", silhouette_avg)\n",
    "    #Finding the average SSE\"\n",
    "    elbow.append(clusterer.inertia_) # Inertia: Sum of distances of samples to their closest cluster center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e18184",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,10))\n",
    "fig.add_subplot(221)\n",
    "plt.plot(range_n_clusters, elbow,'b-',label='Sum of squared error')\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.title(\"WSS Graph\")\n",
    "plt.legend()\n",
    "fig.add_subplot(223)\n",
    "plt.plot(range_n_clusters, ss,'b-',label='Silhouette Score')\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Silhouette Graph\")\n",
    "plt.legend()\n",
    "plt.savefig(\"figures\\trirony_kmeans_multic_wss.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b69aee",
   "metadata": {},
   "source": [
    "## DBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79db2fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = np.arange(0.1, 2, 0.1)\n",
    "min_samples = np.arange(5, 15, 1)\n",
    "ss = []\n",
    "for i in min_samples:\n",
    "    for j in epsilons:\n",
    "        db = DBSCAN(eps=j, min_samples=i, metric='cosine').fit(X_reduced)\n",
    "        labels = db.labels_\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise_ = list(labels).count(-1)\n",
    "        if len(set(labels)) > 2:\n",
    "            silhouette_avg = silhouette_score(X_reduced, labels, metric=\"cosine\")\n",
    "            ss.append(silhouette_avg)\n",
    "            \n",
    "            adj_rand = metrics.adjusted_rand_score(df_sample[\"label\"], labels)\n",
    "            if adj_rand > 0:\n",
    "                print(\"params: \", (i,j))\n",
    "                if silhouette_avg > 0:\n",
    "                    print(\"Silhouette: \", silhouette_avg)\n",
    "                    print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "                    print(\"Adjusted Rand Index: %0.3f\" % adj_rand)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17edbd28",
   "metadata": {},
   "source": [
    "## Visualizing the Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2696f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "# The Best Clustering with K-Means Clustering\n",
    "n_clusters = 3\n",
    "\n",
    "# Initialize the clusterer with n_clusters value and a random generator\n",
    "# seed of 10 for reproducibility.\n",
    "clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "cluster_labels = clusterer.fit_predict(X_reduced)\n",
    "\n",
    "# 1st Plot showing the K-Means Results\n",
    "colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "plt.scatter(\n",
    "    tsne_comps.C1, tsne_comps.C2, marker=\".\", s=50, lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n",
    ")\n",
    "\n",
    "\n",
    "# Labeling the clusters\n",
    "centers = clusterer.cluster_centers_\n",
    "# Draw white circles at cluster centers\n",
    "\"\"\"\n",
    "plt.scatter(\n",
    "    centers[:, 0],\n",
    "    centers[:, 1],\n",
    "    marker=\"o\",\n",
    "    c=\"white\",\n",
    "    alpha=1,\n",
    "    s=200,\n",
    "    edgecolor=\"k\",\n",
    ")\n",
    "\"\"\"\n",
    "#for i, c in enumerate(centers):\n",
    "#    plt.scatter(c[0], c[1], marker=\"$%d$\" % i, alpha=1, s=50, edgecolor=\"k\")\n",
    "\n",
    "plt.title(\"The visualization of the K-Means clustered data.\")\n",
    "plt.xlabel(\"Feature space for the 1st feature\")\n",
    "plt.ylabel(\"Feature space for the 2nd feature\")\n",
    "plt.savefig(\"C:\\\\Users\\\\frat1\\\\Desktop\\\\reddit_kmeans_multic_clusters_tsne.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef1af22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "# The Best Clustering with K-Means Clustering\n",
    "db = DBSCAN(eps=0.5, min_samples=10, metric=\"cosine\").fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "\n",
    "# 2nd Plot showing the DBScan Results\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = labels == k\n",
    "\n",
    "    xy = pca_comps[class_member_mask & core_samples_mask]\n",
    "    plt.scatter(\n",
    "        xy.C1,\n",
    "        xy.C2,\n",
    "        marker=\".\",\n",
    "        #markerfacecolor=tuple(col),\n",
    "        #markeredgecolor=\"k\",\n",
    "        #markersize=14,\n",
    "    )\n",
    "\n",
    "    xy = pca_comps[class_member_mask & ~core_samples_mask]\n",
    "    plt.scatter(\n",
    "        xy.C1,\n",
    "        xy.C2,\n",
    "        marker=\".\",\n",
    "        #markerfacecolor=tuple(col),\n",
    "        #markeredgecolor=\"k\",\n",
    "        #markersize=6,\n",
    "    )\n",
    "\n",
    "plt.title(\"The visualization of the DBScan clustered data.\")\n",
    "plt.xlabel(\"Feature space for the 1st feature\")\n",
    "plt.ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d4f238",
   "metadata": {},
   "source": [
    "### Transform to CausalText Input Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8232e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_sample.drop(columns=['C', 'Unnamed: 0'])\n",
    "df3 = pd.concat([df_merged.reset_index(drop=True), pd.DataFrame(cluster_labels, columns=[\"C\"])], axis=1)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633b2991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(\"inputs/reddit_politics_kmeansC_multiC_v3.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45613831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
